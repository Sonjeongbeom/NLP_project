{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 크기 : \n",
      "ratings_train.txt             14.63MB\n",
      "ratings_test.txt              4.89MB\n",
      "ratings.txt                   19.52MB\n"
     ]
    }
   ],
   "source": [
    "DATA_IN_PATH = \"./dataset/\"\n",
    "print(\"파일 크기 : \")\n",
    "for file in os.listdir(DATA_IN_PATH):\n",
    "    if \"txt\" in file:\n",
    "        print(\n",
    "            file.ljust(30)\n",
    "            + str(round(os.path.getsize(DATA_IN_PATH + file) / 1000000, 2))\n",
    "            + \"MB\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\n",
    "    DATA_IN_PATH + \"ratings_train.txt\", header=0, delimiter=\"\\t\", quoting=3\n",
    ")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                    너무재밓었다그래서보는것을추천한다\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 더빙 진짜 짜증나네요 목소리\n"
     ]
    }
   ],
   "source": [
    "review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", train_data['document'][0])\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아', '더빙', '진짜', '짜증나다', '목소리']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt() \n",
    "review_text = okt.morphs(review_text, stem=True) \n",
    "print (review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['더빙', '진짜', '짜증나다', '목소리']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들', '의', '있', '되', '수', '보', '주', '등', '한'])\n",
    "clean_review = [token for token in review_text if not token in stop_words]\n",
    "clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, okt, remove_stopwords=False, stop_words=[]) :\n",
    "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
    "    word_review = okt.morphs(review_text, stem=True)\n",
    "    if remove_stopwords :\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다'],\n",
       " ['교도소', '이야기', '구먼', '솔직하다', '재미', '없다', '평점', '조정']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_review = list()\n",
    "\n",
    "for review in train_data['document'] :\n",
    "    if type(review) == str :\n",
    "        clean_train_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else :\n",
    "        clean_train_review.append([])\n",
    "    \n",
    "clean_train_review[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_IN_PATH + 'ratings_test.txt', header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "clean_test_review = list()\n",
    "\n",
    "for review in test_data['document'] :\n",
    "    if type(review) == str :\n",
    "        clean_test_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else :\n",
    "        clean_test_review.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
    "\n",
    "word_vocab = tokenizer.word_index\n",
    "MAX_SEQUENCE_LENGTH = 8\n",
    "\n",
    "trian_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "train_labels = np.array(train_data['label'])\n",
    "test_inputs = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './dataset/'\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "data_configs = {}\n",
    "\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_IN_PATH):\n",
    "    os.makedirs(DATA_IN_PATH)\n",
    "\n",
    "np.save(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'wb'), trian_inputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'wb'), train_labels)\n",
    "np.save(open(DATA_IN_PATH + TEST_INPUT_DATA, 'wb'), test_inputs)\n",
    "np.save(open(DATA_IN_PATH + TEST_LABEL_DATA, 'wb'), test_labels)\n",
    "\n",
    "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'), ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
